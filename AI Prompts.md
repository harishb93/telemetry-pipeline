# AI Prompts and Outputs Summary

This document summarizes the prompts given to AI tools and the corresponding outputs during the telemetry pipeline development process.

| Topic/Agenda          | AI Tool Used     | Prompt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Issue/Comment/Behavior                                                                                                                                                                                            |
|-----------------------|------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Project Bootstrapping | GPT-4o           | You are a senior Go systems engineer and a Kubernetes Operator. I'll describe high-level features for a Kubernetes-based telemetry pipeline that uses a custom message queue. STRICT Rule - Do not use external message queues or monitoring tools (no Kafka, RMQ, Prometheus, Grafana, etc.). Confirm you understand and wait for my tasks. Create the base repo structure with module "github.com/harishb93/telemetry-pipeline". This service will have four components to start with: 1. Streamer - reads telemetry(from a CSV file) and manage telemetry data streaming 2. Collector - handle telemetry data collection from multiple sources 3. API Gateway - exposes telemetry via HTTP 4. Queue - a queue for telemetry data processing Include go.mod, .gitignore, and Makefile. All code must compile and include a Dockerfile. Code will be run from a single main.go but functionality(streamer,collector, etc) would change based on "component" flag passed as input                                                                                                                                                                                                                                    | It equated to many tasks and hence had to be split as multiple. Created a single main.go.                                                                                                                         |
| Code                  | GPT-4o           | Implement the "internal/queue" package â€” an in-memory message queue that supports: Publish, subscribe, and Ack, Redelivery if unacked, Concurrent safety, Optional file persistence, Add unit tests. This is the queue component to which streamer component would send the messages and collector component receives the message from.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | It created a "queue" package but code had quite a few deprecated methods and used the basic pub/sub model. It missed test creation                                                                                |
| Code/Test             | GPT-4o           | Remove existing cmd/main.go and update code to have 3 main.go files - cmd/streamer/main.go, cmd/collector/main.go & cmd/apigateway/main.go Implement the "internal/streamer" package that, based on file type, reads CSV rows or JSON array elements and publishes them to the queue at a controlled rate. FileType(CSV/JSON), file path, worker count, and rate per second would be inputs coming as cli flags during initialization through main.go at cmd/streamer/main.go Include tests.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Created streamer/main.go but didn't continue with collector and apigateway                                                                                                                                        |
| Code/Test             | GPT-4o           | Update streamer_test.go with more tests that use the first 2 rows csv and json files present under "tests/data" as data and test against Start functionality. Update streamer to have a Stop functionality as well. Test once completed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Unable to understand the read data from csv file for streamer tests and only updated tests to create and start streamer.                                                                                          |
| Code/Test             | Claude Sonnet 4  | Implement gRPC server in Collector which will be called by api-gateway. api-gateway implements 2 methods - GET /api/v1/gpus(list all gpuIds) and GET /api/v1/gpus/{id}/telemetry(all telemetries of the specific gpuId)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Uses old code of grpc and since it is marked as deprecated, goes in a loop trying to fetch the right code. Multiple attempts to fix deprecated grpc.Dial method.                                                  |
| Deployment Bootstrap  | Claude Sonnet 4  | Generate Helm charts under deploy/helm with subcharts or templates for: telemetry-streamer (Daemonset, Service, ConfigMap for CSV or config), telemetry-collector (Deployment, Service), api-gateway (Deployment, Service, Ingress rules), Values schema values.yaml with replica counts, resource requests/limits, and MQ persistence flags. Add README inside deploy/helm describing install steps on how to install telemetry-streamer, telemetry-collector and api-gateway and what flags can be passed or overridden for each of the charts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | It generated and tested by templatizing. But created everything in a single folder under deploy/helm/templates and made enablement of components flag driven                                                      |
| Deployment Bootstrap  | Claude Sonnet 4  | Provide separate Dockerfiles for each component(cmd/api-gateway, cmd/telemetry-collector, cmf/telemetry-streamer) under deploy/docker/ with name format "<component>.Dockerfile". The Dockerfile must: Use a minimal multi-stage build, Expose relevant ports, Include a small entrypoint.sh if needed to pass flags from ENV. Create a deploy/docker/build-and-push.sh file that would create a start registry if not already running, build all images, tag to localhost:5000 and push to the registry.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Created with 1.21 builder image which will cause issues while building. It also goes above and beyond to create Dockercompose, sample data and a setup.sh                                                         |
| Deployment Bootstrap  | Claude Sonnet 4  | Create/Update Makefile with targets: 1. build (build all binaries) 2. test (run go test ./... with coverage) 3. coverage (create coverage report) 4. docker-build (build Docker images with specified tag - default tag is latest) 5. docker-push (push Docker images) 6. helm-install (install to local cluster with helm) 7. openapi-gen (regenerates api/openapi.yaml from code comments or templates) Assume default registry is localhost:5000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Went ahead and created many more targets along with a MAKEFILE.md                                                                                                                                                 |
| System Tests          | Claude Sonnet 4  | Generate system tests that test the functionality of the components. There should be a setup function and a teardown function for pre and post tests. All of the APIs and connections have to be tested once the setup is complete. The tests can be generated in the folder "/home/harishb/telemetry-pipeline/tests" and run with "make system-tests". These tests shouldn't be run when "make test" is run.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Generates files with compilation errors and not tested. Assumes other tests are not broken when these tests are introduced.                                                                                       |
| Code                  | Claude Sonnet 4  | To the api-gateway component, add 2 more endpoints GET /api/v1/hosts - List the set of hosts (hostname field in csv), GET /api/v1/hosts/<hostName>/gpus - List the gpuId(uuid) of that host (hostname). Update unit and system tests and generate swagger with updated endpoints                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Added endpoints but screwed up test cases.                                                                                                                                                                        |
| Debugging/Logging     | Claude Sonnet 4  | I am having issues with streamer docker container complaining "failed to open file /data/GPU-f2b8d424-ed80-cddd-67d0-00bf52c03704.jsonl: .... permission denied" Fix the code and any possible such instances that can occur in other components as well. Add more logs to the services and have logging level set for all components to info by default but configurable to debug as and when required.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Fixes permission issue in all but added logging only in streamer component.                                                                                                                                       |
| Debugging/CI          | Claude Sonnet 4  | Running make lint throws errors. Fix it. Once fixed, add github ci/actions to enable running the basic checks like lint, tests, build etc.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | Github ci assumed older version of go and local testing wasn't done                                                                                                                                               |
| CI Bootstrap          | Claude Sonnet 4  | Github pipeline seems to be failing. I have updated go version from 1.21/1.22 to 1.25 in ci.yml Verify and fix issues locally, I have installed act tool already.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Tested locally but didn't work because of version compatibility issue in github ci. Had to follow through. Downgraded go version eventually but focussed only on CI leaving dockerfiles                           |
| Code Generation       | Claude Sonnet 4  | Change of plans. Architecturally, by design, code and deployment, we are going to change a few things since it doesn't align with best practices for scalability. Below are the changes. 1. The MQ component is going to be an independent service when deployed(split from collector component) and the streamers are going to publish messages to this MQ service's topic(s). 2. The collectors are going to subscribe to the MQ service topic(s). 3. Persistence layer has to be planned accordingly for the MQ and Collector 4. Api-gateway continues to expose apis that fetch metrics from the collector component                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Started testing by publishing to a topic and from streamer and assumed end to end was done and finished the activity.                                                                                             |
| Prompt Generation     | Claude Sonnet 4  | Generate a prompt for me based on the below requirements. I need a telemetry dashboard component to be built as well. The Dashboard will show the following. 1. Health - api-gateway's health, telemetry-collector's Health and MQ Health using the /health endpoints of individual services/components - "status" field 2. List of Topics - Available at /stats endpoint of mq service - every key under "topics" field 3. No of Pending Messages per topic - Available at /stats endpoint of mq service - "pending_messages" field under every topic under "topics" field 4. Subscriber count per topic - Available at /stats endpoint of mq service - "subscriber_count" field under every topic under "topics" field 5. Queue size per topic - Available at /stats endpoint of mq service - "queue_size" field under every topic under "topics" field 6. Total GPUs across Hosts - Available at /api/v1/gpus of api-gateway - field "total" 7. Table of List of GPUs - Available at /api/v1/gpus of api-gateway - array field "gpus" 8. Total Hosts count - Available at /api/v1/hosts of api-gateway - field "total" 9. Table of List of Hosts- Available at /api/v1/hosts of api-gateway - array field "hosts" | Gave a single long prompt. Had to follow up stating llm has the project context and I need smaller prompts.                                                                                                       |
| Helm Packaging        | Claude Sonnet 4  | You are a Senior Golang developer, a Kubernetes operator and a helm expert. Here are the requirements - You'll make every component helm ready Streamer component - Daemonset - deploy/docker/sample-data/telemetry.csv will be mounted to this(think of having a configmap or add it as part of image in Dockerfile) Dashboard - Deployment and exposed via Ingress MQ and Collector Components - Statefulsets with 1 replica by default. Both of them will have to have storage component(PVC) since they persist files API Gateway - Deployment - Will have volume mount as collector component since collector-data folder is used API gateway, MQ and Collector components would reside in the namespace "gpu-telemetry" Create separate helm charts for each component so that it is deployable on demand separately. Collector has a dependency on MQ when deployed                                                                                                                                                                                                                                                                                                                                           | Created but didn't helm templatize and check if it's valid. Assumed all fields are env and not args. Modified data mount paths in Helm but not Dockerfiles. Created a Configmap with minimal data of csv records. |
| Documentation         | Claude Sonnet 4  | You are now a Product Documentation Expert and you have to write github project documentation. Here are the asks - 1. Code documentation cleanup - Remove all markdown files 2. Have a folder called docs - Should contain the "System Architecture, Design & Flows", Quickstart(setup.sh for Docker setup and quickerstart.sh for Kind setup), Makefile, Deployment(Helm and Dockerfiles), Components(explanation of what each is used for) 3. Have a main README.md on the root folder with High level information of the project and pointing to docs folder's documents for sections and subsections. The documentation should be easily understandable for both a layman as well as an expert - Find the balance. Don't make it too complicated as well or go in depth of what each and every field does in a component.                                                                                                                                                                                                                                                                                                                                                                                        | Goes through the existing README files and assumes I need help only with document placing and little changes. Also, creates a lot of duplications.                                                                |
| Tests                 | Claude Sonnet 4  | Update/Add tests to all of the components and maximize code coverage when 'make test' is run                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Creates tests but doesn't run end to end with make test command. Main.go tests were missed out.                                                                                                                   |
| Debugging             | Claude Sonnet 4  | Fix the lint issues with make lint command                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | It runs once at the start and takes only the current issues and doesn't test again                                                                                                                                |
| Debugging             | Claude Sonnet 4  | Now let's fix the system tests under 'tests' folder and test functionality with 'make system-tests', 'make system-tests-quick' and 'make system-tests-performance' commands                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Took longer to understand the exposed ports and current state. Had to stop and fix the tests manually which included taking decisions.                                                                            |
| Architecture/Design   | Perplexity       | Attached here the architecture/design of my current code. Is this architecturally right for a telemetry pipeline that wants to scale horizontally? What are the changes that needs to be if so? Assume that the collector resides in a single node control plane and streamer services reside in the data plane, one per node.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | It suggested change of design for allowing horizontal scalability and gave recommendations on architectural improvements but with opensource tools.                                                               |
| Architecture/Design   | Perplexity       | The queue, when separated from collector service, will have to reside in control plane and behind the api-gateway, right? That way the streamer services can send the data to the api-gateway of control plane which in turn just diverts the traffic to the messaging queue and the queue is subscribed by the collectors directly without using the api-gateway.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Suggested to keep queue separate but colocated with the collector and use api-gateway only for query, config and metadata apis.                                                                                   |
| Architecture/Design   | Perplexity       | How would authentication and authorization work between streamer, API Gateway, and queue                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | TL;DR Version - Suggested Keycloak, OPA, OIDC, SPIFFE                                                                                                                                                             |
| UI                    | ChatGPT          | Generate a prompt for me based on the below requirements. I need a telemetry dashboard component to be built as well. The Dashboard will show the following. 1. Health - api-gateway's health, telemetry-collector's Health and MQ Health using the /health endpoints of individual services/components - "status" field 2. List of Topics - Available at /stats endpoint of mq service - every key under "topics" field 3. No of Pending Messages per topic - Available at /stats endpoint of mq service - "pending_messages" field under every topic under "topics" field 4. Subscriber count per topic - Available at /stats endpoint of mq service - "subscriber_count" field under every topic under "topics" field 5. Queue size per topic - Available at /stats endpoint of mq service - "queue_size" field under every topic under "topics" field 6. Total GPUs across Hosts - Available at /api/v1/gpus of api-gateway - field "total" 7. Table of List of GPUs - Available at /api/v1/gpus of api-gateway - array field "gpus" 8. Total Hosts count - Available at /api/v1/hosts of api-gateway - field "total" 9. Table of List of Hosts- Available at /api/v1/hosts of api-gateway - array field "hosts" | It generated a list of prompts but had to eventually change based on issue faced                                                                                                                                  |
| Documentation         | Claude Haiku 4.5 | Iterate through all of the .md files, remove duplicates, simplify main README.md and link sub-sections to respective .md file under docs folder                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Had to go through multiple iterations. It either made the README too lengthy and too technical or made it too simple with less to no details provided. Had to make changes myself.                                |
